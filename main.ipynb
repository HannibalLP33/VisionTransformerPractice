{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Drills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.datasets import mnist\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import math \n",
    "import random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Log Settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename = \"logs.log\", format = \"%(asctime)s -- %(message)s\", datefmt='%m/%d/%Y %I:%M:%S %p', level = logging.INFO)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar100.load_data()\n",
    "logging.info(\"Dataset Upload successfully\")\n",
    "logging.info(f\"X training set shape:{X_train.shape}\")\n",
    "logging.info(f\"y training set shape:{y_train.shape}\")\n",
    "logging.info(f\"X test set shape:{X_test.shape}\")\n",
    "logging.info(f\"y training set shape:{y_test.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 256\n",
    "image_size = 72 \n",
    "patch_size = 6\n",
    "num_patches = int(image_size/patch_size)**2\n",
    "patch_plot_size = int(image_size/patch_size)\n",
    "epochs = 1000\n",
    "projection_dim = 512\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize pixels\n",
    "def normalize_images(images):\n",
    "    images = np.asarray(images)/255.0\n",
    "    return images\n",
    "\n",
    "X_train = normalize_images(X_train)\n",
    "X_test = normalize_images(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-28 15:42:42.505908: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "def resize_images(images):\n",
    "    resized_batch = [tf.image.resize(tf.convert_to_tensor(image), size = (image_size, image_size)) for image in images]\n",
    "    resized_batch = tf.convert_to_tensor(resized_batch)\n",
    "\n",
    "    return resized_batch\n",
    "X_train = resize_images(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([50000, 72, 72, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_patches(images, plot_sample = True):\n",
    "    if plot_sample:\n",
    "        #Pick a random image and resize to desired shape\n",
    "        sample_image = images[random.randint(0, len(images))]\n",
    "        sample_image = tf.image.resize(tf.convert_to_tensor(sample_image), size = (image_size, image_size))\n",
    "        logging.info(f\"Sample Image Shape: {sample_image.shape}\")\n",
    "        \n",
    "        # Plotting Original Image\n",
    "        fig = plt.figure(figsize=(7,7))\n",
    "        fig.add_subplot()\n",
    "        plt.imshow(sample_image)\n",
    "        \n",
    "        #Plotting Patched Image\n",
    "        fig = plt.figure(figsize=(7,7))\n",
    "        #Output of extract_patches method is a four dimensional tensor with shape (1, number of columns, number of rows, number of elements per patch)\n",
    "        patched_image = tf.image.extract_patches(tf.expand_dims(sample_image,0),\n",
    "                                                sizes = [1, patch_size, patch_size, 1],\n",
    "                                                strides = [1, patch_size,patch_size, 1],\n",
    "                                                rates = [1,1,1,1],\n",
    "                                                padding = \"VALID\") \n",
    "        patched_image = tf.reshape(patched_image, (1,-1,patched_image.shape[-1])) # Output is reshape to be (1 image, number of patches, number of elements per patch)\n",
    "        for i, ax in enumerate(range(patched_image.shape[1])): #For loop to display each patch in the form of the original image\n",
    "            fig.add_subplot(patch_plot_size, patch_plot_size, i + 1)\n",
    "            plt.imshow(tf.reshape(patched_image[0][i], (patch_size,patch_size,3)))\n",
    "            plt.axis(\"off\")\n",
    "    patched_batch = tf.image.extract_patches(images,\n",
    "                                                sizes = [1, patch_size, patch_size, 1],\n",
    "                                                strides = [1, patch_size,patch_size, 1],\n",
    "                                                rates = [1,1,1,1],\n",
    "                                                padding = \"VALID\")\n",
    "    patched_batch = tf.reshape(patched_batch, (patched_batch.shape[0], -1, patched_batch.shape[-1]))\n",
    "    return patched_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(patched_batch):\n",
    "    patch_projection = keras.layers.Dense(projection_dim)\n",
    "    position_embedding = keras.layers.Embedding(input_dim = num_patches, output_dim = projection_dim)\n",
    "    position = tf.range(start=0, limit=num_patches)\n",
    "    \n",
    "    encoded = [patch_projection(patched_image) + position_embedding(position) for patched_image in patched_batch]\n",
    "\n",
    "    return tf.convert_to_tensor(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50000, 144, 512), dtype=float32, numpy=\n",
       "array([[[-0.49073076, -0.51930964, -0.17580834, ...,  0.16710979,\n",
       "          1.5399585 , -0.9312647 ],\n",
       "        [-0.41420972, -0.5740608 , -0.19866464, ...,  0.16266589,\n",
       "          1.4698322 , -0.9766863 ],\n",
       "        [-0.43352097, -0.54207873, -0.19147143, ...,  0.16187772,\n",
       "          1.5473839 , -0.9648883 ],\n",
       "        ...,\n",
       "        [-0.1787727 , -0.19783251, -0.08460569, ...,  0.05926875,\n",
       "          0.63588905, -0.3523957 ],\n",
       "        [-0.17349389, -0.0281522 , -0.11252379, ...,  0.07671636,\n",
       "          0.28457972, -0.07099849],\n",
       "        [-0.05283094, -0.23042354,  0.06832343, ...,  0.14822179,\n",
       "          0.41385093, -0.33758938]],\n",
       "\n",
       "       [[-0.49215955, -0.51606876, -0.17321283, ...,  0.16896762,\n",
       "          1.5359584 , -0.93404454],\n",
       "        [-0.41775727, -0.5729431 , -0.19383645, ...,  0.16258764,\n",
       "          1.4634867 , -0.98007804],\n",
       "        [-0.43706852, -0.540961  , -0.18664323, ...,  0.16179948,\n",
       "          1.5410384 , -0.96828   ],\n",
       "        ...,\n",
       "        [-0.4169339 , -0.57934946, -0.1412885 , ...,  0.10450336,\n",
       "          1.4853961 , -0.9790416 ],\n",
       "        [-0.46083918, -0.59470016, -0.20627302, ...,  0.16841948,\n",
       "          1.5108616 , -0.91337675],\n",
       "        [-0.4384464 , -0.61451876, -0.15805352, ...,  0.13249877,\n",
       "          1.5083697 , -0.92152214]],\n",
       "\n",
       "       [[-0.4812966 , -0.48528323, -0.17297927, ...,  0.1647689 ,\n",
       "          1.4989139 , -0.9026247 ],\n",
       "        [-0.3915593 , -0.53529644, -0.17499685, ...,  0.16901869,\n",
       "          1.4009051 , -0.93272626],\n",
       "        [-0.41094685, -0.49397096, -0.1625994 , ...,  0.16685265,\n",
       "          1.4789975 , -0.91889447],\n",
       "        ...,\n",
       "        [-0.35715672, -0.34333047, -0.04754754, ...,  0.10151011,\n",
       "          1.0197544 , -0.7711455 ],\n",
       "        [-0.39477158, -0.3665937 , -0.10506976, ...,  0.17113557,\n",
       "          1.0452178 , -0.70182407],\n",
       "        [-0.35701403, -0.55547065, -0.06467158, ...,  0.15581638,\n",
       "          1.179161  , -0.78757334]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.39522764, -0.39505807, -0.17343575, ...,  0.11543046,\n",
       "          1.3514197 , -0.5538635 ],\n",
       "        [-0.14555305, -0.43092644, -0.11894412, ...,  0.1625004 ,\n",
       "          1.1685212 , -0.47901136],\n",
       "        [-0.17362888, -0.4044757 , -0.10292687, ...,  0.1576461 ,\n",
       "          1.2539959 , -0.46266413],\n",
       "        ...,\n",
       "        [-0.3030935 , -0.18689345, -0.02094134, ...,  0.04841435,\n",
       "          0.48329142, -0.65887386],\n",
       "        [-0.3420416 , -0.20242219, -0.08896127, ...,  0.11755665,\n",
       "          0.5895705 , -0.6216652 ],\n",
       "        [-0.32424718, -0.3602552 , -0.11185496, ...,  0.07680914,\n",
       "          0.6145723 , -0.63008565]],\n",
       "\n",
       "       [[-0.17977378, -0.16565338, -0.12622356, ...,  0.11756967,\n",
       "          0.8016869 , -0.33195353],\n",
       "        [-0.09733611, -0.21790503, -0.12823243, ...,  0.1292806 ,\n",
       "          0.70367575, -0.38832894],\n",
       "        [-0.10878763, -0.18002039, -0.13428302, ...,  0.12089835,\n",
       "          0.7652822 , -0.33287832],\n",
       "        ...,\n",
       "        [-0.2559978 , -0.1536731 , -0.0475426 , ...,  0.06285828,\n",
       "          0.54485774, -0.53337866],\n",
       "        [-0.29338637, -0.16001616, -0.1393442 , ...,  0.12436964,\n",
       "          0.56490535, -0.44153148],\n",
       "        [-0.24112265, -0.23651825, -0.08185226, ...,  0.10122406,\n",
       "          0.5780615 , -0.4393964 ]],\n",
       "\n",
       "       [[-0.17239603, -0.23556134, -0.19568405, ..., -0.01591168,\n",
       "          0.47315472, -0.25998685],\n",
       "        [-0.10109887, -0.30294657, -0.22362307, ..., -0.02184398,\n",
       "          0.41895667, -0.31640506],\n",
       "        [-0.12560774, -0.27588132, -0.22802535, ..., -0.02679322,\n",
       "          0.5108894 , -0.31005642],\n",
       "        ...,\n",
       "        [-0.06956823, -0.17818584, -0.0593261 , ..., -0.04092825,\n",
       "          0.29819855, -0.22600056],\n",
       "        [-0.11474807, -0.18315287, -0.11047076, ...,  0.02556552,\n",
       "          0.3185599 , -0.15911858],\n",
       "        [-0.08812232, -0.1906714 , -0.0533979 , ..., -0.00822296,\n",
       "          0.3115345 , -0.1546091 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patched_batch = create_patches(X_train, False)\n",
    "positional_encoding(patched_batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
