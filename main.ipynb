{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Drills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.datasets import mnist\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import math \n",
    "import random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Log Settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename = \"logs.log\", format = \"%(asctime)s -- %(message)s\", datefmt='%m/%d/%Y %I:%M:%S %p', level = logging.INFO)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar100.load_data()\n",
    "logging.info(\"Dataset Upload successfully\")\n",
    "logging.info(f\"X training set shape:{X_train.shape}\")\n",
    "logging.info(f\"y training set shape:{y_train.shape}\")\n",
    "logging.info(f\"X test set shape:{X_test.shape}\")\n",
    "logging.info(f\"y training set shape:{y_test.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 256\n",
    "image_size = 72 \n",
    "patch_size = 6\n",
    "num_patches = int(image_size/patch_size)**2\n",
    "patch_plot_size = int(image_size/patch_size)\n",
    "epochs = 1000\n",
    "projection_dim = 64\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize pixels\n",
    "def normalize_images(images):\n",
    "    images = np.asarray(images)/255.0\n",
    "    return images\n",
    "\n",
    "X_train = normalize_images(X_train)\n",
    "X_test = normalize_images(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-28 16:25:52.978505: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "def resize_images(images):\n",
    "    resized_batch = [tf.image.resize(tf.convert_to_tensor(image), size = (image_size, image_size)) for image in images]\n",
    "    return tf.convert_to_tensor(resized_batch)\n",
    "\n",
    "X_train = resize_images(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_patches(images, plot_sample = True):\n",
    "    if plot_sample:\n",
    "        #Pick a random image and resize to desired shape\n",
    "        sample_image = images[random.randint(0, len(images))]\n",
    "        sample_image = tf.image.resize(tf.convert_to_tensor(sample_image), size = (image_size, image_size))\n",
    "        logging.info(f\"Sample Image Shape: {sample_image.shape}\")\n",
    "        \n",
    "        # Plotting Original Image\n",
    "        fig = plt.figure(figsize=(7,7))\n",
    "        fig.add_subplot()\n",
    "        plt.imshow(sample_image)\n",
    "        \n",
    "        #Plotting Patched Image\n",
    "        fig = plt.figure(figsize=(7,7))\n",
    "        #Output of extract_patches method is a four dimensional tensor with shape (1, number of columns, number of rows, number of elements per patch)\n",
    "        patched_image = tf.image.extract_patches(tf.expand_dims(sample_image,0),\n",
    "                                                sizes = [1, patch_size, patch_size, 1],\n",
    "                                                strides = [1, patch_size,patch_size, 1],\n",
    "                                                rates = [1,1,1,1],\n",
    "                                                padding = \"VALID\") \n",
    "        patched_image = tf.reshape(patched_image, (1,-1,patched_image.shape[-1])) # Output is reshape to be (1 image, number of patches, number of elements per patch)\n",
    "        for i, ax in enumerate(range(patched_image.shape[1])): #For loop to display each patch in the form of the original image\n",
    "            fig.add_subplot(patch_plot_size, patch_plot_size, i + 1)\n",
    "            plt.imshow(tf.reshape(patched_image[0][i], (patch_size,patch_size,3)))\n",
    "            plt.axis(\"off\")\n",
    "    patched_batch = tf.image.extract_patches(images,\n",
    "                                                sizes = [1, patch_size, patch_size, 1],\n",
    "                                                strides = [1, patch_size,patch_size, 1],\n",
    "                                                rates = [1,1,1,1],\n",
    "                                                padding = \"VALID\")\n",
    "    patched_batch = tf.reshape(patched_batch, (patched_batch.shape[0], -1, patched_batch.shape[-1]))\n",
    "    return patched_batch\n",
    "\n",
    "patched_batch = create_patches(X_train, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(patched_batch):\n",
    "    patch_projection = keras.layers.Dense(projection_dim)\n",
    "    position_embedding = keras.layers.Embedding(input_dim = num_patches, output_dim = projection_dim)\n",
    "    position = tf.range(start=0, limit=num_patches)\n",
    "    encoded = [patch_projection(patched_image)+ position_embedding(position) for patched_image in patched_batch]\n",
    "\n",
    "    return tf.convert_to_tensor(encoded)\n",
    "\n",
    "encoded_batch = positional_encoding(patched_batch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PreProcessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
