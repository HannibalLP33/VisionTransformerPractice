{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Drills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.datasets import mnist\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import math \n",
    "import random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Log Settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename = \"logs.log\", format = \"%(asctime)s -- %(message)s\", datefmt='%m/%d/%Y %I:%M:%S %p', level = logging.INFO)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar100.load_data()\n",
    "logging.info(\"Dataset Upload successfully\")\n",
    "logging.info(f\"X training set shape:{X_train.shape}\")\n",
    "logging.info(f\"y training set shape:{y_train.shape}\")\n",
    "logging.info(f\"X test set shape:{X_test.shape}\")\n",
    "logging.info(f\"y training set shape:{y_test.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = X_train\n",
    "y_train = tf.keras.utils.to_categorical(y_train,100)\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-4\n",
    "batch_size = 256\n",
    "image_size = 72 \n",
    "patch_size = 6\n",
    "num_patches = int(image_size/patch_size)**2\n",
    "patch_plot_size = int(image_size/patch_size)\n",
    "epochs = 1000\n",
    "projection_dim = 32\n",
    "mlp_dim = 128\n",
    "transformer_layer = 1\n",
    "multiheadattention_heads = 4\n",
    "num_classes = 100\n",
    "transformer_units = [\n",
    "    projection_dim **2,\n",
    "    projection_dim\n",
    "]\n",
    "mlp_units = [2048, 1024]\n",
    "input_shape = (num_patches, projection_dim)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_images(images):\n",
    "    images /=255\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(images):\n",
    "    resized_batch = [tf.image.resize(tf.convert_to_tensor(image), size = (image_size, image_size)) for image in images]\n",
    "    return tf.convert_to_tensor(resized_batch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_patches(images, plot_sample = True):\n",
    "    if plot_sample:\n",
    "        #Pick a random image and resize to desired shape\n",
    "        sample_image = images[random.randint(0, len(images))]\n",
    "        sample_image = tf.image.resize(tf.convert_to_tensor(sample_image), size = (image_size, image_size))\n",
    "        logging.info(f\"Sample Image Shape: {sample_image.shape}\")\n",
    "        \n",
    "        # Plotting Original Image\n",
    "        fig = plt.figure(figsize=(7,7))\n",
    "        fig.add_subplot()\n",
    "        plt.imshow(sample_image)\n",
    "        \n",
    "        #Plotting Patched Image\n",
    "        fig = plt.figure(figsize=(7,7))\n",
    "        #Output of extract_patches method is a four dimensional tensor with shape (1, number of columns, number of rows, number of elements per patch)\n",
    "        patched_image = tf.image.extract_patches(tf.expand_dims(sample_image,0),\n",
    "                                                sizes = [1, patch_size, patch_size, 1],\n",
    "                                                strides = [1, patch_size,patch_size, 1],\n",
    "                                                rates = [1,1,1,1],\n",
    "                                                padding = \"VALID\") \n",
    "        patched_image = tf.reshape(patched_image, (1,-1,patched_image.shape[-1])) # Output is reshape to be (1 image, number of patches, number of elements per patch)\n",
    "        for i, ax in enumerate(range(patched_image.shape[1])): #For loop to display each patch in the form of the original image\n",
    "            fig.add_subplot(patch_plot_size, patch_plot_size, i + 1)\n",
    "            plt.imshow(tf.reshape(patched_image[0][i], (patch_size,patch_size,3)))\n",
    "            plt.axis(\"off\")\n",
    "    patched_batch = tf.image.extract_patches(images,\n",
    "                                                sizes = [1, patch_size, patch_size, 1],\n",
    "                                                strides = [1, patch_size,patch_size, 1],\n",
    "                                                rates = [1,1,1,1],\n",
    "                                                padding = \"VALID\")\n",
    "    patched_batch = tf.reshape(patched_batch, (patched_batch.shape[0], -1, patched_batch.shape[-1]))\n",
    "    return patched_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(patched_batch):\n",
    "    patch_projection = keras.layers.Dense(projection_dim)\n",
    "    position_embedding = keras.layers.Embedding(input_dim = num_patches, output_dim = projection_dim)\n",
    "    position = tf.range(start=0, limit=num_patches)\n",
    "    encoded = [patch_projection(patched_image)+ position_embedding(position) for patched_image in patched_batch]\n",
    "\n",
    "    return tf.convert_to_tensor(encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = resize_images(X_train)\n",
    "X_train = normalize_images(X_train)\n",
    "patched_batch = create_patches(X_train, True)\n",
    "encoded_batch = positional_encoding(patched_batch) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_block(x, hidden_units, dropout_rate):\n",
    "    for unit in hidden_units:\n",
    "        x = keras.layers.Dense(unit, activation = tf.nn.gelu)(x)\n",
    "        x = keras.layers.Dropout(rate = dropout_rate)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder():\n",
    "    inputs = keras.Input(shape = input_shape)\n",
    "    # print(inputs)\n",
    "    # norm_inputs = normalize_images(inputs)\n",
    "    # print(norm_inputs)\n",
    "    # resized_inputs = resize_images(norm_inputs)\n",
    "    # print(resized_inputs)\n",
    "    # patched_inputs = create_patches(resized_inputs, False)\n",
    "    # encoded_inputs = positional_encoding(patched_inputs)\n",
    "    \n",
    "    \n",
    "    for _ in range(transformer_layer):\n",
    "        layer1 = keras.layers.LayerNormalization(epsilon = 1e-6)(inputs)\n",
    "        layer1 = keras.layers.MultiHeadAttention(num_heads = multiheadattention_heads, key_dim = projection_dim, dropout=0.1)(layer1, layer1)\n",
    "        skip1 = keras.layers.Add()([layer1, inputs])\n",
    "        final_layer = keras.layers.LayerNormalization(epsilon = 1e-6)(skip1)\n",
    "        final_layer = mlp_block(final_layer, transformer_units, dropout_rate = 0.1)\n",
    "        skip2 = keras.layers.Add()([final_layer, skip1])\n",
    "        \n",
    "    # encoder_output = keras.layers.LayerNormalization(epsilon = 1e-6)(skip2)\n",
    "    # encoder_output = keras.layers.Flatten()(encoder_output)\n",
    "    # encoder_output = keras.layers.Dropout(0.5)(encoder_output)\n",
    "    encoder_output = tf.reduce_mean(skip2, axis = 1)\n",
    "    features = mlp_block(encoder_output, mlp_units, dropout_rate = 0.5)\n",
    "    \n",
    "    logit = keras.layers.Dense(units = num_classes, kernel_initializer=tf.keras.initializers.zeros)(features)\n",
    "    \n",
    "    model = keras.Model(inputs = inputs, outputs = logit)\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model):\n",
    "    optimizer = tf.optimizers.Adam(learning_rate=learning_rate, decay=weight_decay)\n",
    "    model.compile(optimizer=optimizer, \n",
    "                  loss = keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                  metrics = keras.metrics.CategoricalAccuracy(name = \"Cat_Accuracy\"))\n",
    "    history = model.fit(\n",
    "        x = encoded_batch,\n",
    "        y = y_train,\n",
    "        batch_size = batch_size,\n",
    "        epochs = epochs\n",
    "    )\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = encoder()\n",
    "\n",
    "history = train_model(transformer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
